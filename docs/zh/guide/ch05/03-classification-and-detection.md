---
title: 5.3 åˆ†ç±»å’Œæ£€æµ‹
description: åŒ»å­¦å›¾åƒåˆ†æä¸­çš„æ·±åº¦å­¦ä¹ åˆ†ç±»å’Œæ£€æµ‹æŠ€æœ¯
---

# 5.3 åˆ†ç±»å’Œæ£€æµ‹

> "åŒ»å­¦å›¾åƒåˆ†ç±»å’Œæ£€æµ‹æ­£åœ¨ä»è®¡ç®—æœºè¾…åŠ©æ£€æµ‹ï¼ˆCADeï¼‰å‘è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ï¼ˆCADxï¼‰å‘å±•ï¼Œå¹¶é€æ¸æˆä¸ºä¸´åºŠåŒ»ç”Ÿçš„é‡è¦åŠ©æ‰‹ã€‚" â€”â€” AIåŒ»å­¦å½±åƒå‘å±•è¶‹åŠ¿

åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†å­¦ä¹ äº†é¢„å¤„ç†æŠ€æœ¯å’ŒåŸºäºU-Netçš„åˆ†å‰²æ–¹æ³•ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬è¿›å…¥åŒ»å­¦å›¾åƒåˆ†æçš„å¦ä¸€ä¸ªé‡è¦é¢†åŸŸï¼š**åˆ†ç±»å’Œæ£€æµ‹**ã€‚ä¸åˆ†å‰²çš„åƒç´ çº§ç²¾åº¦è¦æ±‚ä¸åŒï¼Œåˆ†ç±»å’Œæ£€æµ‹æ›´å…³æ³¨å‡†ç¡®åœ°è¯†åˆ«ç–¾ç—…å’Œå®šä½ç—…ç¶ã€‚

åŒ»å­¦å›¾åƒåˆ†ç±»å’Œæ£€æµ‹é¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼šæç«¯çš„ç±»åˆ«ä¸å¹³è¡¡ï¼ˆæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹å¯è¾¾1:1000ï¼‰ã€å¾®å°çš„ç—…ç¶å°ºå¯¸ã€å›¾åƒè´¨é‡å˜åŒ–ï¼Œä»¥åŠå¯¹é«˜ç²¾åº¦å’Œé«˜å¬å›ç‡çš„è¦æ±‚ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚

---

## ğŸ” åˆ†ç±»æ£€æµ‹æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”

### åŸºç¡€ä»»åŠ¡å®šä¹‰

#### å›¾åƒåˆ†ç±»

**å›¾åƒåˆ†ç±»**ç¡®å®šå›¾åƒæ˜¯å¦åŒ…å«ç‰¹å®šçš„ç–¾ç—…æˆ–å¼‚å¸¸ï¼š

- **äºŒåˆ†ç±»**ï¼šæ­£å¸¸ vs å¼‚å¸¸
- **å¤šç±»åˆ†ç±»**ï¼šç‰¹å®šç–¾ç—…ç±»å‹è¯†åˆ«
- **å¤šæ ‡ç­¾åˆ†ç±»**ï¼šä¸€å¼ å›¾åƒå¯èƒ½åŒ…å«å¤šç§ç–¾ç—…

#### ç›®æ ‡æ£€æµ‹

**ç›®æ ‡æ£€æµ‹**ä¸ä»…è¯†åˆ«ç–¾ç—…ï¼Œè¿˜ç¡®å®šå…¶ä½ç½®ï¼š

- **è¾¹ç•Œæ¡†æ£€æµ‹**ï¼šæ¡†å‡ºç—…ç¶åŒºåŸŸ
- **ç—…ç¶å®šä½**ï¼šæä¾›ç²¾ç¡®åæ ‡
- **å¤šç—…ç¶æ£€æµ‹**ï¼šåŒæ—¶æ£€æµ‹å¤šä¸ªç—…ç¶

| ä»»åŠ¡ç±»å‹ | è¾“å…¥ | è¾“å‡º | ä¸´åºŠåº”ç”¨ | éš¾åº¦ç­‰çº§ |
|-----------|-------|--------|---------------------|-----------------|
| **åˆ†ç±»** | å®Œæ•´åŒ»å­¦å›¾åƒ | ç–¾ç—…æ ‡ç­¾/ç±»åˆ« | åˆç­›ã€åˆ†è¯Š | â­â­ |
| **æ£€æµ‹** | å®Œæ•´åŒ»å­¦å›¾åƒ | è¾¹ç•Œæ¡† + ç±»åˆ« | ç—…ç¶å®šä½ã€æ‰‹æœ¯è§„åˆ’ | â­â­â­ |
| **åˆ†å‰²** | å®Œæ•´åŒ»å­¦å›¾åƒ | åƒç´ çº§æ©ç  | ç²¾ç¡®æµ‹é‡ã€3Dé‡å»º | â­â­â­â­ |

### åŒ»å­¦ç‰¹æ®Šæ€§

#### ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜

åŒ»å­¦æˆåƒæ•°æ®é€šå¸¸å­˜åœ¨ä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡ï¼š

```python
def analyze_class_imbalance(dataset):
    """
    åˆ†æåŒ»å­¦æ•°æ®é›†ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡
    """
    class_counts = {}
    for label in dataset.labels:
        class_counts[label] = class_counts.get(label, 0) + 1

    total_samples = len(dataset)
    imbalance_ratios = {}

    for class_name, count in class_counts.items():
        ratio = count / total_samples
        imbalance_ratios[class_name] = {
            'count': count,
            'percentage': ratio * 100,
            'imbalance_factor': max(class_counts.values()) / count
        }

    return imbalance_ratios

# ç¤ºä¾‹è¾“å‡º
# {
#     'normal': {'count': 9500, 'percentage': 95.0, 'imbalance_factor': 1.0},
#     'pneumonia': {'count': 300, 'percentage': 3.0, 'imbalance_factor': 31.7},
#     'tuberculosis': {'count': 150, 'percentage': 1.5, 'imbalance_factor': 63.3},
#     'cancer': {'count': 50, 'percentage': 0.5, 'imbalance_factor': 190.0}
# }
```

#### ä¸ç¡®å®šæ€§å’Œå¯è§£é‡Šæ€§

åŒ»å­¦è¯Šæ–­éœ€è¦é«˜å¯è§£é‡Šæ€§ï¼š

```python
class MedicalClassificationModel(nn.Module):
    """
    å¯è§£é‡Šçš„åŒ»å­¦åˆ†ç±»æ¨¡å‹
    """
    def __init__(self, backbone, num_classes):
        super().__init__()
        self.backbone = backbone
        self.classifier = nn.Linear(backbone.feature_dim, num_classes)
        self.attention_map = nn.Conv2d(backbone.feature_dim, 1, 1)

    def forward(self, x):
        features = self.backbone.extract_features(x)

        # åˆ†ç±»é¢„æµ‹
        logits = self.classifier(F.adaptive_avg_pool2d(features, 1).flatten(1))
        probs = F.softmax(logits, dim=1)

        # æ³¨æ„åŠ›å›¾å¯è§†åŒ–
        attention = F.sigmoid(self.attention_map(features))

        return {
            'predictions': probs,
            'attention_maps': attention,
            'features': features
        }
```

---

## ğŸ¥ 2D CNN Xçº¿å›¾åƒåˆ†ç±»æŠ€æœ¯

### Xçº¿åˆ†ç±»ç‰¹å¾

#### æ•´ä½“å›¾åƒç†è§£

Xçº¿åˆ†ç±»éœ€è¦ç†è§£æ•´ä½“ä¸Šä¸‹æ–‡ï¼š

- **å…¨å±€ç‰¹å¾**ï¼šæ•´ä½“å™¨å®˜å½¢æ€
- **å±€éƒ¨ç‰¹å¾**ï¼šç‰¹å®šç—…ç¶å¾è±¡
- **ç›¸å¯¹ä½ç½®**ï¼šè§£å‰–ç»“æ„é—´çš„ç©ºé—´å…³ç³»

![èƒ¸éƒ¨Xçº¿åˆ†ç±»](https://www.researchgate.net/publication/341837493/figure/fig1/AS:894194425237504@1590191057416/Chest-X-ray-image-classification-using-deep-learning-The-model-learns-automatically-the.ppm)
*åŸºäºæ·±åº¦å­¦ä¹ çš„èƒ¸éƒ¨Xçº¿åˆ†ç±»ï¼Œæ¨¡å‹è‡ªåŠ¨å­¦ä¹ ç–¾ç—…ç‰¹å¾*

### ç»å…¸2D CNNæ¶æ„

#### åŸºäºResNetçš„åŒ»å­¦åˆ†ç±»

```python
import torch.nn as nn
import torch.nn.functional as F
from torchvision.models import resnet50

class MedicalResNet(nn.Module):
    """
    åŸºäºResNetçš„åŒ»å­¦å›¾åƒåˆ†ç±»æ¨¡å‹
    """
    def __init__(self, num_classes, pretrained=True, dropout_rate=0.5):
        super().__init__()

        # åŠ è½½é¢„è®­ç»ƒResNet
        self.backbone = resnet50(pretrained=pretrained)

        # ä¿®æ”¹ç¬¬ä¸€å±‚ä»¥é€‚åº”åŒ»å­¦ç°åº¦å›¾åƒ
        self.backbone.conv1 = nn.Conv2d(
            1, 64, kernel_size=7, stride=2, padding=3, bias=False
        )

        # æ›¿æ¢åˆ†ç±»å™¨
        feature_dim = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()

        # è‡ªå®šä¹‰åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(dropout_rate),
            nn.Linear(feature_dim, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate * 0.5),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)
```

#### DenseNetçš„ä¼˜åŠ¿

**DenseNet**ç‰¹åˆ«é€‚åˆåŒ»å­¦å›¾åƒåˆ†ç±»ï¼š

```python
class DenseNetMedical(nn.Module):
    """
    åŸºäºDenseNetçš„åŒ»å­¦åˆ†ç±»æ¨¡å‹
    """
    def __init__(self, num_classes, growth_rate=32, block_config=(6, 12, 24, 16)):
        super().__init__()

        # DenseNetç‰¹å¾æå–å™¨
        self.features = self._make_dense_layers(growth_rate, block_config)

        # åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.BatchNorm2d(block_config[-1] * growth_rate),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(block_config[-1] * growth_rate, num_classes)
        )

    def _make_dense_layers(self, growth_rate, block_config):
        """
        æ„å»ºDenseNetå±‚
        """
        layers = []

        # åˆå§‹å·ç§¯
        layers += [
            nn.Conv2d(1, 2 * growth_rate, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(2 * growth_rate),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=2, padding=1)
        ]

        # å¯†é›†å—
        num_features = 2 * growth_rate
        for i, num_layers in enumerate(block_config):
            layers.append(self._make_dense_block(num_features, num_layers, growth_rate))
            num_features += num_layers * growth_rate

            if i != len(block_config) - 1:
                layers.append(self._make_transition_layer(num_features, num_features // 2))
                num_features = num_features // 2

        return nn.Sequential(*layers)

    def _make_dense_block(self, in_channels, num_layers, growth_rate):
        """
        æ„å»ºå¯†é›†å—
        """
        layers = []
        for _ in range(num_layers):
            layers.append(self._make_dense_layer(in_channels, growth_rate))
            in_channels += growth_rate
        return nn.Sequential(*layers)

    def _make_dense_layer(self, in_channels, growth_rate):
        """
        æ„å»ºå¯†é›†å±‚
        """
        return nn.Sequential(
            nn.BatchNorm2d(in_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels, 4 * growth_rate, 1, bias=False),
            nn.BatchNorm2d(4 * growth_rate),
            nn.ReLU(inplace=True),
            nn.Conv2d(4 * growth_rate, growth_rate, 3, padding=1, bias=False)
        )
```

### æ•°æ®ä¸å¹³è¡¡å¤„ç†ç­–ç•¥

#### æŸå¤±å‡½æ•°è®¾è®¡

```python
class FocalLoss(nn.Module):
    """
    Focal Lossï¼šè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
    """
    def __init__(self, alpha=1, gamma=2, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class BalancedCrossEntropyLoss(nn.Module):
    """
    å¹³è¡¡äº¤å‰ç†µæŸå¤±
    """
    def __init__(self, class_weights=None):
        super().__init__()
        self.class_weights = class_weights

    def forward(self, inputs, targets):
        if self.class_weights is not None:
            weight = self.class_weights[targets]
            ce_loss = F.cross_entropy(inputs, targets, weight=weight, reduction='none')
        else:
            ce_loss = F.cross_entropy(inputs, targets, reduction='none')

        return ce_loss.mean()
```

#### æ•°æ®é‡‡æ ·ç­–ç•¥

```python
class BalancedSampler(torch.utils.data.Sampler):
    """
    å¹³è¡¡é‡‡æ ·å™¨ï¼šç¡®ä¿æ¯ä¸ªbatchæœ‰å‡è¡¡çš„æ ·æœ¬
    """
    def __init__(self, dataset, samples_per_class):
        self.dataset = dataset
        self.samples_per_class = samples_per_class

        # æŒ‰ç±»åˆ«åˆ†ç»„
        self.class_indices = {}
        for idx, label in enumerate(dataset.labels):
            if label not in self.class_indices:
                self.class_indices[label] = []
            self.class_indices[label].append(idx)

    def __iter__(self):
        batch = []
        for _ in range(len(self) // self.samples_per_class):
            # ä»æ¯ä¸ªç±»åˆ«éšæœºé€‰æ‹©æ ·æœ¬
            sampled_indices = []
            for class_indices in self.class_indices.values():
                if len(class_indices) > 0:
                    sampled_idx = np.random.choice(class_indices)
                    sampled_indices.append(sampled_idx)

            batch.extend(sampled_indices)

        np.random.shuffle(batch)
        return iter(batch)

    def __len__(self):
        return len(self.dataset)
```

---

## ğŸ§  3D CNNä½“ç§¯æ•°æ®åˆ†æ

### ä»2Dåˆ°3Dï¼šæŒ‘æˆ˜ä¸æœºé‡

#### 3Dæ•°æ®ç‰¹å¾

ä½“ç§¯åŒ»å­¦æ•°æ®ï¼ˆCTã€MRIï¼‰å…·æœ‰ç‹¬ç‰¹ç‰¹å¾ï¼š

| ç‰¹å¾ | 2Då›¾åƒ | 3Dä½“ç§¯ |
|---------|----------|-----------|
| **ç©ºé—´ä¿¡æ¯** | å¹³é¢ä¸Šä¸‹æ–‡ | å®Œæ•´3Dç©ºé—´å…³ç³» |
| **è®¡ç®—å¤æ‚åº¦** | O(HÃ—W) | O(HÃ—WÃ—D) |
| **å†…å­˜éœ€æ±‚** | MB | GB |
| **å±‚é—´ä¿¡æ¯** | ä¸¢å¤± | ä¿ç•™ |
| **ä¸´åºŠä»·å€¼** | å±€éƒ¨è¯Šæ–­ | ç»¼åˆåˆ†æ |

#### 3Då·ç§¯æ“ä½œ

```python
class Conv3DBlock(nn.Module):
    """
    3Då·ç§¯å—
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding, bias=False)
        self.bn = nn.BatchNorm3d(out_channels)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        return self.relu(self.bn(self.conv(x)))

class ResNet3DBlock(nn.Module):
    """
    3Dæ®‹å·®å—
    """
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        self.conv1 = Conv3DBlock(in_channels, out_channels, stride=stride)
        self.conv2 = nn.Sequential(
            nn.Conv3d(out_channels, out_channels, 3, padding=1, bias=False),
            nn.BatchNorm3d(out_channels)
        )

        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, 1, stride, bias=False),
                nn.BatchNorm3d(out_channels)
            )

    def forward(self, x):
        residual = self.shortcut(x)
        out = self.conv1(x)
        out = self.conv2(out)
        out += residual
        return F.relu(out)
```

### 3D CNNæ¶æ„è®¾è®¡

#### åŒ»å­¦3D ResNet

```python
class Medical3DResNet(nn.Module):
    """
    ç”¨äºä½“ç§¯åŒ»å­¦å›¾åƒåˆ†ç±»çš„3D ResNet
    """
    def __init__(self, block, layers, num_classes=2):
        super().__init__()

        self.in_channels = 64

        # åˆå§‹å·ç§¯
        self.conv1 = nn.Sequential(
            nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)
        )

        # æ®‹å·®å—
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)

        # åˆ†ç±»å¤´
        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()

    def _make_layer(self, block, out_channels, blocks, stride=1):
        layers = []
        layers.append(block(self.in_channels, out_channels, stride))
        self.in_channels = out_channels * block.expansion

        for _ in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))

        return nn.Sequential(*layers)

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.conv1(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x

# æ¨¡å‹å®ä¾‹åŒ–
def create_medical_3d_resnet(num_classes=2):
    return Medical3DResNet(ResNet3DBlock, [2, 2, 2, 2], num_classes)
```

#### 3D DenseNetæ¶æ„

```python
class DenseBlock3D(nn.Module):
    """
    3Då¯†é›†å—
    """
    def __init__(self, num_layers, in_channels, growth_rate):
        super().__init__()
        self.layers = nn.ModuleList()

        for i in range(num_layers):
            layer = nn.Sequential(
                nn.BatchNorm3d(in_channels + i * growth_rate),
                nn.ReLU(inplace=True),
                nn.Conv3d(in_channels + i * growth_rate, 4 * growth_rate, 1, bias=False),
                nn.BatchNorm3d(4 * growth_rate),
                nn.ReLU(inplace=True),
                nn.Conv3d(4 * growth_rate, growth_rate, 3, padding=1, bias=False)
            )
            self.layers.append(layer)

    def forward(self, x):
        features = [x]

        for layer in self.layers:
            new_features = layer(torch.cat(features, dim=1))
            features.append(new_features)

        return torch.cat(features, dim=1)
```

### å†…å­˜ä¼˜åŒ–ç­–ç•¥

#### åŸºäºPatchesçš„è®­ç»ƒ

```python
class Patch3DDataset(torch.utils.data.Dataset):
    """
    3D patchæ•°æ®é›†
    """
    def __init__(self, volume_path, label_path, patch_size=(64, 64, 64), stride=32):
        self.patch_size = patch_size
        self.stride = stride

        # åŠ è½½ä½“ç§¯å’Œæ ‡ç­¾
        self.volume = nib.load(volume_path).get_fdata()
        self.label = nib.load(label_path).get_fdata()

        # ç”Ÿæˆpatchåæ ‡
        self.patches = self._generate_patches()

    def _generate_patches(self):
        """
        ç”Ÿæˆ3D patchåæ ‡
        """
        patches = []
        D, H, W = self.volume.shape
        pd, ph, pw = self.patch_size

        for d in range(0, D - pd + 1, self.stride):
            for h in range(0, H - ph + 1, self.stride):
                for w in range(0, W - pw + 1, self.stride):
                    patch_volume = self.volume[d:d+pd, h:h+ph, w:w+pw]
                    patch_label = self.label[d:d+pd, h:h+ph, w:w+pw]

                    # è¿‡æ»¤æ‰èƒŒæ™¯patches
                    if np.sum(patch_label > 0) > 0.1 * np.prod(self.patch_size):
                        patches.append((d, h, w))

        return patches

    def __getitem__(self, idx):
        d, h, w = self.patches[idx]
        pd, ph, pw = self.patch_size

        volume_patch = self.volume[d:d+pd, h:h+ph, w:w+pw]
        label_patch = self.label[d:d+pd, h:h+ph, w:w+pw]

        # å½’ä¸€åŒ–
        volume_patch = self._normalize_volume(volume_patch)

        return torch.FloatTensor(volume_patch).unsqueeze(0), torch.LongTensor([label_patch.max()])
```

#### æ¢¯åº¦æ£€æŸ¥ç‚¹

```python
from torch.utils.checkpoint import checkpoint

class MemoryEfficient3DNet(nn.Module):
    """
    å†…å­˜é«˜æ•ˆçš„3Dç½‘ç»œ
    """
    def __init__(self):
        super().__init__()
        self.layer1 = self._create_layer(1, 64)
        self.layer2 = self._create_layer(64, 128)
        self.layer3 = self._create_layer(128, 256)
        self.layer4 = self._create_layer(256, 512)

    def _create_layer(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv3d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœå†…å­˜
        x1 = checkpoint(self.layer1, x)
        x2 = checkpoint(self.layer2, x1)
        x3 = checkpoint(self.layer3, x2)
        x4 = checkpoint(self.layer4, x3)

        return x4
```

---

## ğŸ”¬ å…¨å¹»ç¯ç‰‡å›¾åƒå¤šç¤ºä¾‹å­¦ä¹ 

### å…¨å¹»ç¯ç‰‡å›¾åƒæŒ‘æˆ˜

#### WSIç‰¹å¾

**å…¨å¹»ç¯ç‰‡å›¾åƒï¼ˆWSIï¼‰**å…·æœ‰ç‹¬ç‰¹ç‰¹å¾ï¼š

- **è¶…é«˜åˆ†è¾¨ç‡**ï¼š100,000Ã—100,000åƒç´ æˆ–æ›´é«˜
- **å·¨å¤§æ–‡ä»¶å¤§å°**ï¼šæ•°GB
- **å¯å˜æ”¾å¤§å€æ•°**ï¼šä¸åŒç‰©é•œï¼ˆ4xã€10xã€20xã€40xï¼‰
- **ä»…æœ‰å¹»ç¯ç‰‡çº§æ ‡ç­¾**ï¼šé€šå¸¸åªçŸ¥é“æ‚£è€…æ˜¯å¦æ‚£æœ‰ç™Œç—‡

![å…¨å¹»ç¯ç‰‡å›¾åƒåˆ†æå·¥ä½œæµç¨‹](https://www.researchgate.net/publication/335782688/figure/fig1/AS:803675432949761@1568948590481/The-workflow-of-multiple-instance-learning-based-prostate-cancer-detection-in-gigapixel.png)
*åŸºäºMILçš„åƒå…†åƒç´ WSIç™Œç—‡æ£€æµ‹å·¥ä½œæµç¨‹*

### MILåŸºç¡€

#### é—®é¢˜å½¢å¼åŒ–

åœ¨MILä¸­ï¼Œä¸€å¼ å¹»ç¯ç‰‡è¢«è§†ä¸ºä¸€ä¸ª**åŒ…ï¼ˆbagï¼‰**ï¼Œä»ä¸­æå–çš„patchesæ˜¯**å®ä¾‹ï¼ˆinstancesï¼‰**ï¼š

- **åŒ…æ ‡ç­¾**ï¼šå·²çŸ¥ï¼ˆå¦‚ç™Œæ€§/æ­£å¸¸ï¼‰
- **å®ä¾‹æ ‡ç­¾**ï¼šæœªçŸ¥ï¼ˆå“ªäº›patchesåŒ…å«ç™Œç—‡ï¼‰
- **å‡è®¾**ï¼šå¦‚æœåŒ…æ˜¯é˜³æ€§çš„ï¼Œè‡³å°‘æœ‰ä¸€ä¸ªå®ä¾‹æ˜¯é˜³æ€§çš„

```python
class MILDataset(torch.utils.data.Dataset):
    """
    å¤šç¤ºä¾‹å­¦ä¹ æ•°æ®é›†
    """
    def __init__(self, wsi_paths, labels, patch_size=256, magnification=20):
        self.wsi_paths = wsi_paths
        self.labels = labels
        self.patch_size = patch_size
        self.magnification = magnification

        # é¢„æå–patchesæˆ–åŠ¨æ€æå–
        self.patch_cache = {}

    def extract_patches(self, wsi_path, num_patches=100):
        """
        ä»WSIæå–patches
        """
        wsi = openslide.OpenSlide(wsi_path)

        # è·å–å›¾åƒå°ºå¯¸
        level = self._get_best_level(wsi, self.magnification)
        dimensions = wsi.level_dimensions[level]

        patches = []
        for _ in range(num_patches):
            # éšæœºé‡‡æ ·
            x = np.random.randint(0, dimensions[0] - self.patch_size)
            y = np.random.randint(0, dimensions[1] - self.patch_size)

            patch = wsi.read_region((x, y), level,
                                  (self.patch_size, self.patch_size))
            patch = patch.convert('RGB')

            # ç»„ç»‡è¿‡æ»¤
            if self._is_tissue_patch(patch):
                patches.append(np.array(patch))

        return patches

    def _is_tissue_patch(self, patch, threshold=0.1):
        """
        æ£€æŸ¥patchæ˜¯å¦åŒ…å«ç»„ç»‡
        """
        # è½¬æ¢åˆ°HSVç©ºé—´è¿›è¡Œç»„ç»‡æ£€æµ‹
        hsv = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)

        # ç»„ç»‡é€šå¸¸å‡ºç°åœ¨ç‰¹å®šçš„Hã€SèŒƒå›´å†…
        tissue_mask = (hsv[:, :, 0] > 0.1) & (hsv[:, :, 1] > 0.1)
        tissue_ratio = np.sum(tissue_mask) / patch.size

        return tissue_ratio > threshold

    def __getitem__(self, idx):
        if idx not in self.patch_cache:
            self.patch_cache[idx] = self.extract_patches(self.wsi_paths[idx])

        patches = self.patch_cache[idx]
        label = self.labels[idx]

        # è½¬æ¢ä¸ºtensor
        patches_tensor = torch.FloatTensor(np.array(patches)).permute(0, 3, 1, 2)
        label_tensor = torch.LongTensor([label])

        return patches_tensor, label_tensor
```

### MILç®—æ³•å®ç°

#### å®ä¾‹çº§æ³¨æ„åŠ›

```python
class AttentionMIL(nn.Module):
    """
    åŸºäºæ³¨æ„åŠ›çš„å¤šç¤ºä¾‹å­¦ä¹ æ¨¡å‹
    """
    def __init__(self, input_size=256*256*3, hidden_size=512, attention_size=256, num_classes=2):
        super().__init__()

        # ç‰¹å¾æå–å™¨
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.5)
        )

        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.Sequential(
            nn.Linear(hidden_size, attention_size),
            nn.Tanh(),
            nn.Linear(attention_size, 1)
        )

        # åˆ†ç±»å™¨
        self.classifier = nn.Linear(hidden_size, num_classes)

    def forward(self, bag):
        """
        å‰å‘ä¼ æ’­
        Args:
            bag: (batch_size, num_instances, channels, height, width)
        """
        batch_size, num_instances, C, H, W = bag.shape

        # é‡å¡‘ä»¥å¤„ç†æ¯ä¸ªå®ä¾‹
        bag = bag.view(-1, C, H, W)

        # ç‰¹å¾æå–
        features = self.feature_extractor(bag.view(bag.size(0), -1))

        # é‡å¡‘å›bagæ ¼å¼
        features = features.view(batch_size, num_instances, -1)

        # æ³¨æ„åŠ›è®¡ç®—
        attention_weights = self.attention(features)  # (batch_size, num_instances, 1)
        attention_weights = F.softmax(attention_weights, dim=1)

        # åŠ æƒæ± åŒ–
        weighted_features = torch.sum(features * attention_weights, dim=1)

        # åˆ†ç±»
        logits = self.classifier(weighted_features)

        return {
            'logits': logits,
            'attention_weights': attention_weights,
            'instance_features': features
        }

    def calculate_loss(self, outputs, targets, attention_reg_strength=0.001):
        """
        è®¡ç®—MILæŸå¤±
        """
        # åˆ†ç±»æŸå¤±
        classification_loss = F.cross_entropy(outputs['logits'], targets)

        # æ³¨æ„åŠ›æ­£åˆ™åŒ–ï¼ˆé˜²æ­¢æ³¨æ„åŠ›åªé›†ä¸­åœ¨å•ä¸ªå®ä¾‹ä¸Šï¼‰
        attention_entropy = -torch.mean(
            torch.sum(outputs['attention_weights'] *
                     torch.log(outputs['attention_weights'] + 1e-8), dim=1)
        )

        total_loss = classification_loss - attention_reg_strength * attention_entropy

        return total_loss
```

#### æ·±åº¦MILæ¡†æ¶

```python
class DeepMIL(nn.Module):
    """
    æ·±åº¦å¤šç¤ºä¾‹å­¦ä¹ æ¡†æ¶
    """
    def __init__(self, backbone='resnet50', mil_type='attention', num_classes=2):
        super().__init__()

        self.backbone = self._create_backbone(backbone)
        self.mil_layer = self._create_mil_layer(mil_type)
        self.classifier = nn.Linear(2048, num_classes)  # ResNet50è¾“å‡ºç»´åº¦

    def _create_backbone(self, backbone_name):
        """
        åˆ›å»ºCNN backbone
        """
        if backbone_name == 'resnet50':
            from torchvision.models import resnet50
            backbone = resnet50(pretrained=True)
            # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚
            backbone = nn.Sequential(*list(backbone.children())[:-1])

        return backbone

    def _create_mil_layer(self, mil_type):
        """
        åˆ›å»ºMILå±‚
        """
        if mil_type == 'attention':
            return AttentionMIL()
        elif mil_type == 'max_pooling':
            return nn.AdaptiveMaxPool2d(1)
        elif mil_type == 'mean_pooling':
            return nn.AdaptiveAvgPool2d(1)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„MILç±»å‹: {mil_type}")

    def forward(self, bag):
        """
        å‰å‘ä¼ æ’­
        Args:
            bag: (batch_size, num_instances, 3, H, W)
        """
        batch_size, num_instances = bag.shape[:2]

        # é‡å¡‘ä»¥å¤„ç†æ¯ä¸ªå®ä¾‹
        instances = bag.view(-1, *bag.shape[2:])

        # ç‰¹å¾æå–
        with torch.no_grad():
            features = self.backbone(instances)  # (batch_size * num_instances, 2048, 1, 1)
            features = features.view(features.size(0), -1)  # å±•å¹³

        # é‡å¡‘ä¸ºbagæ ¼å¼
        features = features.view(batch_size, num_instances, -1)

        # MILèšåˆ
        if isinstance(self.mil_layer, AttentionMIL):
            mil_output = self.mil_layer({'features': features})
            bag_features = mil_output['bag_features']
            attention_weights = mil_output['attention_weights']
        else:
            features = features.view(batch_size * num_instances, -1)
            bag_features = self.mil_layer(features.view(batch_size, num_instances, -1, 1, 1))
            bag_features = bag_features.view(batch_size, -1)
            attention_weights = None

        # åˆ†ç±»
        logits = self.classifier(bag_features)

        return {
            'logits': logits,
            'attention_weights': attention_weights,
            'bag_features': bag_features
        }
```

### å¯è§†åŒ–å’Œå¯è§£é‡Šæ€§

#### æ³¨æ„åŠ›å›¾å¯è§†åŒ–

```python
def visualize_attention_map(wsi_path, model, attention_weights, patch_coordinates, save_path):
    """
    åœ¨WSIä¸Šå¯è§†åŒ–æ³¨æ„åŠ›å›¾
    """
    import matplotlib.pyplot as plt
    from matplotlib.patches import Rectangle

    # åŠ è½½WSI
    wsi = openslide.OpenSlide(wsi_path)

    # è·å–ç¼©ç•¥å›¾
    thumbnail = wsi.get_thumbnail((wsi.dimensions[0] // 10, wsi.dimensions[1] // 10))

    fig, ax = plt.subplots(1, 1, figsize=(15, 10))
    ax.imshow(thumbnail)

    # ç»˜åˆ¶æ³¨æ„åŠ›æƒé‡
    scale_factor = 10  # ç¼©ç•¥å›¾ç¼©æ”¾å› å­

    for (x, y), weight in zip(patch_coordinates, attention_weights):
        rect = Rectangle((x // scale_factor, y // scale_factor),
                        256 // scale_factor, 256 // scale_factor,
                        linewidth=1, edgecolor='red',
                        facecolor='red', alpha=weight.item())
        ax.add_patch(rect)

    ax.set_title('æ³¨æ„åŠ›å›¾å¯è§†åŒ–')
    ax.axis('off')
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
```

---

## ğŸ¯ åŒ»å­¦å½±åƒç›®æ ‡æ£€æµ‹æŠ€æœ¯

### åŒ»å­¦ç›®æ ‡æ£€æµ‹ç‰¹å¾

#### ä¸ä¸€èˆ¬ç›®æ ‡æ£€æµ‹çš„å·®å¼‚

| ç‰¹å¾ | ä¸€èˆ¬ç›®æ ‡æ£€æµ‹ | åŒ»å­¦ç›®æ ‡æ£€æµ‹ |
|---------|------------------------|--------------------------|
| **ç›®æ ‡** | å¸¸è§ç‰©ä½“ | ç—…ç¶ã€ç»“èŠ‚ã€å¼‚å¸¸ |
| **å°ºå¯¸å˜åŒ–** | é€‚ä¸­ | å¾ˆå¤§ï¼ˆåƒç´ åˆ°å…¨å›¾ï¼‰ |
| **å½¢çŠ¶** | è§„åˆ™ | ä¸è§„åˆ™ã€è¾¹ç•Œæ¨¡ç³Š |
| **ç±»åˆ«å¹³è¡¡** | å¹³è¡¡ | æåº¦ä¸å¹³è¡¡ |
| **æ ‡æ³¨æˆæœ¬** | ä½ | å¾ˆé«˜ï¼ˆä¸“å®¶æ ‡æ³¨ï¼‰ |
| **è¦æ±‚** | é€Ÿåº¦ | å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ |

#### ç‰¹æ®ŠæŒ‘æˆ˜

1. **å¾®å°ç—…ç¶**ï¼šä¸€äº›ç»“èŠ‚å¯èƒ½åªæœ‰å‡ ä¸ªåƒç´ 
2. **ä½å¯¹æ¯”åº¦**ï¼šä¸å‘¨å›´ç»„ç»‡å¯†åº¦ç›¸ä¼¼
3. **è¾¹ç•Œæ¨¡ç³Š**ï¼šç—…ç¶è¾¹ç•Œä¸è§„åˆ™
4. **ç±»åˆ«ä¸å¹³è¡¡**ï¼šè´Ÿæ ·æœ¬è¿œå¤šäºæ­£æ ·æœ¬

### ç»å…¸ç›®æ ‡æ£€æµ‹æ¡†æ¶

#### Faster R-CNNé€‚åº”

```python
import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

class MedicalFasterRCNN(nn.Module):
    """
    ä¸ºåŒ»å­¦æˆåƒé€‚é…çš„Faster R-CNN
    """
    def __init__(self, num_classes, pretrained=True):
        super().__init__()

        # åŠ è½½é¢„è®­ç»ƒFaster R-CNN
        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)

        # ä¸ºç°åº¦å›¾åƒä¿®æ”¹
        self.model.backbone.body.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

        # æ›¿æ¢é¢„æµ‹å™¨
        in_features = self.model.roi_heads.box_predictor.cls_score.in_features
        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

        # è°ƒæ•´anchorä»¥é€‚åº”åŒ»å­¦æˆåƒ
        self._adjust_anchors()

    def _adjust_anchors(self):
        """
        ä¸ºåŒ»å­¦ç—…ç¶è°ƒæ•´anchoræ¡†å¤§å°
        """
        # åŒ»å­¦ç—…ç¶é€šå¸¸è¾ƒå°
        anchor_sizes = ((4, 8, 16), (8, 16, 32), (16, 32, 64))
        aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)

        self.model.rpn.anchor_generator.sizes = anchor_sizes
        self.model.rpn.anchor_generator.aspect_ratios = aspect_ratios

    def forward(self, images, targets=None):
        return self.model(images, targets)

def train_medical_detector(model, dataloader, optimizer, device, num_epochs):
    """
    è®­ç»ƒåŒ»å­¦ç›®æ ‡æ£€æµ‹å™¨
    """
    model.train()

    for epoch in range(num_epochs):
        for images, targets in dataloader:
            images = list(image.to(device) for image in images)
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

            # å‰å‘ä¼ æ’­
            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            losses.backward()
            optimizer.step()

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {losses.item():.4f}")
```

#### YOLOé€‚åº”

```python
class MedicalYOLO(nn.Module):
    """
    ä¸ºåŒ»å­¦æˆåƒé€‚é…çš„YOLO
    """
    def __init__(self, num_classes, input_size=512, grid_size=16):
        super().__init__()

        self.input_size = input_size
        self.grid_size = grid_size
        self.num_classes = num_classes
        self.num_boxes = 2  # æ¯ä¸ªç½‘æ ¼å•å…ƒçš„boxæ•°é‡

        # Backboneï¼ˆç®€åŒ–Darknetï¼‰
        self.backbone = self._create_backbone()

        # æ£€æµ‹å¤´
        self.detection_head = self._create_detection_head()

    def _create_backbone(self):
        """
        åˆ›å»ºbackboneç½‘ç»œ
        """
        layers = []

        # ç¬¬ä¸€ä¸ªå—
        layers += [
            nn.Conv2d(1, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1),
            nn.Conv2d(128, 64, 1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.1),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2),
        ]

        return nn.Sequential(*layers)

    def _create_detection_head(self):
        """
        åˆ›å»ºæ£€æµ‹å¤´
        """
        feature_size = 128 * (self.input_size // 32) ** 2
        grid_total = self.grid_size ** 2

        return nn.Sequential(
            nn.Linear(feature_size, 1024),
            nn.LeakyReLU(0.1),
            nn.Dropout(0.5),
            nn.Linear(1024, grid_total * self.num_boxes * (5 + self.num_classes)),
            nn.Sigmoid()
        )

    def forward(self, x):
        features = self.backbone(x)
        batch_size = features.size(0)
        features = features.view(batch_size, -1)

        detections = self.detection_head(features)
        detections = detections.view(
            batch_size, self.grid_size, self.grid_size,
            self.num_boxes, 5 + self.num_classes
        )

        return detections
```

### æŸå¤±å‡½æ•°è®¾è®¡

#### ç›®æ ‡æ£€æµ‹çš„Focal Loss

```python
class FocalLossForDetection(nn.Module):
    """
    åŒ»å­¦ç›®æ ‡æ£€æµ‹çš„Focal Loss
    """
    def __init__(self, alpha=0.25, gamma=2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma

    def forward(self, predictions, targets):
        """
        Args:
            predictions: (batch_size, grid_size, grid_size, num_boxes, 5 + num_classes)
            targets: (batch_size, grid_size, grid_size, num_boxes, 5 + num_classes)
        """
        # ç›®æ ‡æ€§æŸå¤±
        pred_obj = predictions[..., 4]
        target_obj = targets[..., 4]

        focal_loss = self.alpha * (1 - pred_obj) ** self.gamma * \
                    F.binary_cross_entropy(pred_obj, target_obj, reduction='none')

        # ç±»åˆ«æŸå¤±ï¼ˆä»…å¯¹ç›®æ ‡å•å…ƒï¼‰
        pred_class = predictions[..., 5:]
        target_class = targets[..., 5:]

        class_loss = F.binary_cross_entropy(pred_class, target_class, reduction='none')

        # ä»…åœ¨æœ‰ç›®æ ‡çš„åœ°æ–¹åº”ç”¨
        class_loss = class_loss * target_obj.unsqueeze(-1)

        # åæ ‡æŸå¤±ï¼ˆä»…å¯¹ç›®æ ‡å•å…ƒï¼‰
        pred_coord = predictions[..., :4]
        target_coord = targets[..., :4]

        coord_loss = F.mse_loss(pred_coord, target_coord, reduction='none')
        coord_loss = coord_loss.sum(dim=-1) * target_obj

        # æ€»æŸå¤±
        total_loss = focal_loss + class_loss.sum(dim=-1) + coord_loss

        return total_loss.mean()
```

### åŒ»å­¦ä¸“ç”¨ä¼˜åŒ–ç­–ç•¥

#### éš¾è´Ÿæ ·æœ¬æŒ–æ˜

```python
class HardNegativeMiner:
    """
    åŒ»å­¦ç›®æ ‡æ£€æµ‹çš„éš¾è´Ÿæ ·æœ¬æŒ–æ˜
    """
    def __init__(self, negative_ratio=3):
        self.negative_ratio = negative_ratio

    def mine_hard_negatives(self, predictions, targets):
        """
        æŒ–æ˜éš¾è´Ÿæ ·æœ¬
        """
        # è®¡ç®—æ¯ä¸ªé¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„IoU
        ious = self._calculate_ious(predictions, targets)

        # è¯†åˆ«è´Ÿæ ·æœ¬ï¼ˆIoU < é˜ˆå€¼ï¼‰
        negative_mask = ious < 0.3
        negative_indices = torch.where(negative_mask)

        if len(negative_indices[0]) == 0:
            return None

        # è®¡ç®—è´Ÿæ ·æœ¬çš„ç½®ä¿¡åº¦åˆ†æ•°
        negative_confidences = predictions[negative_indices][:, 4]

        # é€‰æ‹©éš¾è´Ÿæ ·æœ¬ï¼ˆç½®ä¿¡åº¦æœ€é«˜çš„è´Ÿæ ·æœ¬ï¼‰
        num_negatives = min(len(negative_confidences),
                          self.negative_ratio * len(torch.where(ious >= 0.5)[0]))

        _, hard_indices = torch.topk(negative_confidences, num_negatives)

        return negative_indices[0][hard_indices]

    def _calculate_ious(self, predictions, targets):
        """
        è®¡ç®—é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†ä¹‹é—´çš„IoU
        """
        # ç®€åŒ–çš„IoUè®¡ç®—
        pred_boxes = predictions[:, :4]
        target_boxes = targets[:, :4]

        # è®¡ç®—äº¤é›†
        inter_x1 = torch.max(pred_boxes[:, 0], target_boxes[:, 0])
        inter_y1 = torch.max(pred_boxes[:, 1], target_boxes[:, 1])
        inter_x2 = torch.min(pred_boxes[:, 2], target_boxes[:, 2])
        inter_y2 = torch.min(pred_boxes[:, 3], target_boxes[:, 3])

        inter_area = torch.clamp(inter_x2 - inter_x1, min=0) * \
                    torch.clamp(inter_y2 - inter_y1, min=0)

        # è®¡ç®—å¹¶é›†
        pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])
        target_area = (target_boxes[:, 2] - target_boxes[:, 0]) * (target_boxes[:, 3] - target_boxes[:, 1])

        union_area = pred_area + target_area - inter_area

        return inter_area / (union_area + 1e-8)
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”ä¸å®è·µæŒ‡å—

### è¯„ä¼°æŒ‡æ ‡

#### åˆ†ç±»æŒ‡æ ‡

```python
def calculate_medical_classification_metrics(y_true, y_pred, y_prob=None):
    """
    è®¡ç®—åŒ»å­¦åˆ†ç±»è¯„ä¼°æŒ‡æ ‡
    """
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report

    metrics = {}

    # åŸºç¡€æŒ‡æ ‡
    metrics['accuracy'] = accuracy_score(y_true, y_pred)
    metrics['precision'] = precision_score(y_true, y_pred, average='weighted')
    metrics['recall'] = recall_score(y_true, y_pred, average='weighted')
    metrics['f1_score'] = f1_score(y_true, y_pred, average='weighted')

    # åŒ»å­¦ä¸“ç”¨æŒ‡æ ‡
    metrics['sensitivity'] = recall_score(y_true, y_pred, pos_label=1)  # çœŸé˜³æ€§ç‡
    metrics['specificity'] = recall_score(y_true, y_pred, pos_label=0,
                                         average='binary')  # çœŸé˜´æ€§ç‡

    # AUC-ROC
    if y_prob is not None:
        metrics['auc_roc'] = roc_auc_score(y_true, y_prob[:, 1])

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    metrics['confusion_matrix'] = cm

    # è¯¦ç»†æŠ¥å‘Š
    metrics['classification_report'] = classification_report(y_true, y_pred)

    return metrics
```

#### æ£€æµ‹æŒ‡æ ‡

```python
def calculate_detection_metrics(predictions, targets, iou_threshold=0.5):
    """
    è®¡ç®—ç›®æ ‡æ£€æµ‹æŒ‡æ ‡
    """
    detections = []
    ground_truths = []

    for pred, target in zip(predictions, targets):
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        det_boxes = pred['boxes'].cpu().numpy()
        det_scores = pred['scores'].cpu().numpy()
        det_labels = pred['labels'].cpu().numpy()

        gt_boxes = target['boxes'].cpu().numpy()
        gt_labels = target['labels'].cpu().numpy()

        # è®¡ç®—IoUçŸ©é˜µ
        iou_matrix = calculate_iou_matrix(det_boxes, gt_boxes)

        # åŒ¹é…é¢„æµ‹ä¸çœŸå®å€¼
        matches = match_detections(iou_matrix, iou_threshold)

        detections.extend(det_boxes)
        ground_truths.extend(gt_boxes)

    # è®¡ç®—mAP
    mAP = calculate_map(detections, ground_truths, iou_threshold)

    return {
        'mAP': mAP,
        'total_predictions': len(detections),
        'total_ground_truths': len(ground_truths)
    }

def calculate_map(detections, ground_truths, iou_threshold=0.5):
    """
    è®¡ç®—å¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰
    """
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    detections.sort(key=lambda x: x['score'], reverse=True)

    # è®¡ç®—ç²¾ç¡®åº¦å’Œå¬å›ç‡
    tp = 0
    fp = 0
    fn = len(ground_truths)

    precisions = []
    recalls = []

    for det in detections:
        # æ£€æŸ¥æ˜¯å¦ä¸ºçœŸé˜³æ€§
        is_tp = False
        for gt in ground_truths:
            if calculate_iou(det['box'], gt['box']) > iou_threshold:
                tp += 1
                fn -= 1
                is_tp = True
                break

        if not is_tp:
            fp += 1

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0

        precisions.append(precision)
        recalls.append(recall)

    # è®¡ç®—AP
    ap = calculate_ap_from_pr(precisions, recalls)

    return ap
```

### æ¨¡å‹é€‰æ‹©æŒ‡å—

#### ä»»åŠ¡é©±åŠ¨çš„æ¨¡å‹é€‰æ‹©

![åŒ»å­¦å›¾åƒåˆ†ææ¨¡å‹é€‰æ‹©æŒ‡å—](./mermaid-assets/rendered-images/05-model-selection-zh.png)
*å›¾ï¼šæ ¹æ®åŒ»å­¦å›¾åƒçš„æ•°æ®ç±»å‹ï¼ˆ2D Xçº¿ã€3D CT/MRIã€å…¨å¹»ç¯ç‰‡å›¾åƒï¼‰å’Œä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚*[ğŸ“„ [Mermaidæºæ–‡ä»¶](./mermaid-assets/source-files/05-model-selection-zh.mmd)]

<details>
<summary>ğŸ“– æŸ¥çœ‹åŸå§‹Mermaidä»£ç </summary>

```mermaid
flowchart TD
    A[åŒ»å­¦å›¾åƒåˆ†æä»»åŠ¡] --> B{æ•°æ®ç±»å‹ï¼Ÿ}

    B -->|2D Xçº¿| C{ä»»åŠ¡ç±»å‹ï¼Ÿ}
    B -->|3D CT/MRI| D{ä»»åŠ¡ç±»å‹ï¼Ÿ}
    B -->|å…¨å¹»ç¯ç‰‡å›¾åƒ| E{ä»»åŠ¡ç±»å‹ï¼Ÿ}

    C -->|åˆ†ç±»| F[ResNet/DenseNet<br>+ è¿ç§»å­¦ä¹ ]
    C -->|æ£€æµ‹| G[Faster R-CNN/YOLO<br>+ Anchorè°ƒæ•´]

    D -->|åˆ†ç±»| H[3D ResNet/3D DenseNet<br>+ åŸºäºPatchçš„è®­ç»ƒ]
    D -->|åˆ†å‰²| I[3D U-Net/V-Net<br>+ è·³è·ƒè¿æ¥]

    E -->|åˆ†ç±»| J[æ³¨æ„åŠ›MIL<br>+ ç»„ç»‡è¿‡æ»¤]
    E -->|æ£€æµ‹| K[Patchçº§æ£€æµ‹<br>+ èšåˆ]

    F --> L[æœ€ä½³å®è·µ]
    G --> L
    H --> L
    I --> L
    J --> L
    K --> L

    L --> M[ç±»åˆ«ä¸å¹³è¡¡å¤„ç†]
    L --> N[æ•°æ®å¢å¼º]
    L --> O[é›†æˆæ–¹æ³•]
    L --> P[äº¤å‰éªŒè¯]
```
</details>

#### æ€§èƒ½æ¯”è¾ƒ

| æ¨¡å‹ | æ•°æ®ç±»å‹ | ä»»åŠ¡ | mAP/å‡†ç¡®ç‡ | å†…å­˜ä½¿ç”¨ | è®­ç»ƒæ—¶é—´ | ä¸´åºŠé€‚ç”¨æ€§ |
|-------|-----------|------|--------------|--------------|---------------|---------------------|
| **ResNet50** | 2D Xçº¿ | åˆ†ç±» | 0.85-0.92 | 2GB | ä¸­ç­‰ | â­â­â­â­â­ |
| **DenseNet121** | 2D Xçº¿ | åˆ†ç±» | 0.87-0.94 | 2.5GB | ä¸­ç­‰ | â­â­â­â­â­ |
| **3D ResNet** | 3D CT/MRI | åˆ†ç±» | 0.82-0.89 | 8GB | é«˜ | â­â­â­â­â­ |
| **Faster R-CNN** | 2D Xçº¿ | æ£€æµ‹ | 0.78-0.85 | 4GB | é«˜ | â­â­â­â­â­ |
| **YOLOv5** | 2D Xçº¿ | æ£€æµ‹ | 0.75-0.82 | 1.5GB | ä½ | â­â­â­â­â­ |
| **æ³¨æ„åŠ›MIL** | WSI | åˆ†ç±» | 0.80-0.88 | 6GB | éå¸¸é«˜ | â­â­â­â­â­ |

---

## ğŸ¯ æŠ€æœ¯è¦ç‚¹ä¸å‘å±•è¶‹åŠ¿

### 1. åˆ†ç±»æŠ€æœ¯
- **2D CNNç”¨äºXçº¿**ï¼šåŸºäºResNetã€DenseNetçš„è¿ç§»å­¦ä¹ 
- **3D CNNç”¨äºä½“ç§¯æ•°æ®**ï¼š3D ResNetã€å†…å­˜ä¼˜åŒ–ç­–ç•¥
- **æ•°æ®ä¸å¹³è¡¡å¤„ç†**ï¼šFocal Lossã€å¹³è¡¡é‡‡æ ·

### 2. æ£€æµ‹ç­–ç•¥
- **ç»å…¸æ¡†æ¶**ï¼šFaster R-CNNã€YOLOåŒ»å­¦é€‚åº”
- **åŒ»å­¦ä¸“ç”¨**ï¼šéš¾è´Ÿæ ·æœ¬æŒ–æ˜ã€anchorè°ƒæ•´
- **è¯„ä¼°æŒ‡æ ‡**ï¼šmAPã€IoUã€ä¸´åºŠæŒ‡æ ‡

### 3. å…¨å¹»ç¯ç‰‡å›¾åƒåˆ†æ
- **MILæ¡†æ¶**ï¼šæ³¨æ„åŠ›æœºåˆ¶ã€å®ä¾‹çº§å­¦ä¹ 
- **å†…å­˜æ•ˆç‡**ï¼šåŸºäºPatchçš„å¤„ç†ã€ç¼“å­˜ç­–ç•¥
- **å¯è§£é‡Šæ€§**ï¼šæ³¨æ„åŠ›å›¾å¯è§†åŒ–

### 4. æœ€ä½³å®è·µ
- **ä¸´åºŠè¦æ±‚**ï¼šå‡†ç¡®ç‡ç¬¬ä¸€ï¼Œé€Ÿåº¦ç¬¬äºŒ
- **æ•°æ®è´¨é‡**ï¼šé«˜è´¨é‡æ ‡æ³¨ã€å¤šä¸­å¿ƒéªŒè¯
- **æ³•è§„åˆè§„**ï¼šæ¨¡å‹å¯è§£é‡Šæ€§ã€å†³ç­–æ”¯æŒ

### 5. æœªæ¥è¶‹åŠ¿
- **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆæˆåƒå’Œä¸´åºŠæ•°æ®çš„ç»¼åˆåˆ†æ
- **å¼±ç›‘ç£å­¦ä¹ **ï¼šå‡å°‘æ ‡æ³¨éœ€æ±‚
- **è”é‚¦å­¦ä¹ **ï¼šå¤šä¸­å¿ƒåˆä½œã€éšç§ä¿æŠ¤

---

::: info ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ 
ç°åœ¨ä½ å·²ç»æŒæ¡äº†åŒ»å­¦å›¾åƒåˆ†ç±»å’Œæ£€æµ‹çš„æ ¸å¿ƒæŠ€æœ¯ã€‚åœ¨ä¸‹ä¸€èŠ‚ï¼ˆ5.4 å›¾åƒå¢å¼ºå’Œæ¢å¤ï¼‰ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•é€šè¿‡å…ˆè¿›çš„æ•°æ®å¢å¼ºæŠ€æœ¯å…‹æœæ•°æ®ç¨€ç¼ºæŒ‘æˆ˜ï¼Œå¹¶æ¢å¤ä¸¢å¤±çš„å›¾åƒä¿¡æ¯ã€‚
:::