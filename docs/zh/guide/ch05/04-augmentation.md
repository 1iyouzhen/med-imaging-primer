---
title: 5.4 å›¾åƒå¢å¼ºä¸æ¢å¤
description: åŒ»å­¦å›¾åƒå¢å¼ºä¸æ¢å¤æŠ€æœ¯
---

# 5.4 å›¾åƒå¢å¼ºä¸æ¢å¤

> "æ•°æ®å¢å¼ºæ˜¯åŒ»å­¦å½±åƒæ·±åº¦å­¦ä¹ çš„'è´«ç©·è€…çš„åˆ©å™¨'ï¼Œè€Œå›¾åƒæ¢å¤åˆ™æ˜¯'æ—¶é—´æœºå™¨'ï¼Œèƒ½å¤Ÿé‡å»ºä¸¢å¤±çš„ä¿¡æ¯ã€‚" â€” åŒ»å­¦å½±åƒç ”ç©¶ä¸­çš„ç»å…¸æ¯”å–»

åœ¨å‰é¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†é¢„å¤„ç†ã€åˆ†å‰²ã€åˆ†ç±»å’Œæ£€æµ‹çš„æ ¸å¿ƒæŠ€æœ¯ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ¢è®¨ä¸¤ä¸ªå…³é”®çš„ä¸»é¢˜ï¼š**å›¾åƒå¢å¼º**å’Œ**å›¾åƒæ¢å¤**ã€‚è¿™ä¸¤ä¸ªæŠ€æœ¯è™½ç„¶ç›®æ ‡ä¸åŒï¼Œä½†éƒ½è‡´åŠ›äºæå‡åŒ»å­¦å›¾åƒçš„è´¨é‡å’Œä¿¡æ¯é‡ã€‚

åŒ»å­¦å½±åƒé¢†åŸŸé¢ä¸´ç€ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼šæ•°æ®ç¨€ç¼ºæ€§ã€é‡‡é›†æ¡ä»¶çš„å·®å¼‚ã€å™ªå£°å¹²æ‰°ã€ä»¥åŠä¸å¯é¿å…çš„å›¾åƒè´¨é‡ä¸‹é™ã€‚å›¾åƒå¢å¼ºé€šè¿‡ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®æ¥æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œè€Œå›¾åƒæ¢å¤åˆ™è‡´åŠ›äºä¿®å¤é€€åŒ–çš„å›¾åƒè´¨é‡ã€‚è®©æˆ‘ä»¬æ·±å…¥æ¢ç´¢è¿™ä¸¤ä¸ªé‡è¦é¢†åŸŸã€‚

---

## ğŸ¨ åŒ»å­¦å›¾åƒå¢å¼ºåŸºç¡€æŠ€æœ¯

### åŸºç¡€æ•°æ®å¢å¼º

#### å‡ ä½•å˜æ¢

åŒ»å­¦å›¾åƒçš„å‡ ä½•å˜æ¢éœ€è¦ç‰¹æ®Šçš„è€ƒè™‘ï¼Œå› ä¸ºè§£å‰–ç»“æ„çš„ä½ç½®å…³ç³»ä¸èƒ½éšæ„æ”¹å˜ï¼š

```python
class MedicalAugmentation:
    """åŒ»å­¦å›¾åƒå¢å¼ºå·¥å…·"""

    def __init__(self, image_size=(256, 256), modality='CT'):
        self.image_size = image_size
        self.modality = modality
        self._setup_modality_parameters()

    def spatial_transform(self, image, label=None):
        """ç©ºé—´å˜æ¢å¢å¼º"""
        # 1. æ—‹è½¬ï¼ˆå°è§’åº¦ä¿æŒè§£å‰–åˆç†æ€§ï¼‰
        # 2. å¹³ç§»ï¼ˆå°å¹…åº¦ä½ç§»ï¼‰
        # 3. ç¼©æ”¾ï¼ˆä¿æŒæ•´ä½“æ¯”ä¾‹ï¼‰
        # 4. å¼¹æ€§å˜å½¢ï¼ˆåŒ»å­¦å›¾åƒå¢å¼ºçš„ç‹ç‰ŒæŠ€æœ¯ï¼‰
        return enhanced_image

    def intensity_transform(self, image):
        """å¼ºåº¦å˜æ¢å¢å¼º"""
        # 1. å¯¹æ¯”åº¦è°ƒæ•´
        # 2. äº®åº¦è°ƒæ•´
        # 3. æ¨¡æ€ç‰¹å®šå™ªå£°æ·»åŠ 
        return enhanced_image
```

[ğŸ“– **å®Œæ•´ä»£ç ç¤ºä¾‹**: `data_augmentation/`](../../../ch05-code-examples/) - åŒ…å«å®Œæ•´çš„åŒ»å­¦å›¾åƒå¢å¼ºå®ç°ã€2D/3Då˜æ¢å’Œæ¨¡æ€é€‚é…åŠŸèƒ½]

**è¿è¡Œç»“æœåˆ†æï¼š**

```
åˆ›å»ºCTå›¾åƒå¢å¼ºæµæ°´çº¿:
  å›¾åƒå°ºå¯¸: (256, 256)
  å¢å¼ºæ¦‚ç‡: 0.8
  æ—‹è½¬èŒƒå›´: Â±5Â°
  å¹³ç§»èŒƒå›´: Â±5.0%
  ç¼©æ”¾èŒƒå›´: Â±10.0%

æ‰§è¡Œç©ºé—´å˜æ¢å¢å¼º...
  åº”ç”¨æ—‹è½¬: 3.2Â°
  åº”ç”¨å¹³ç§»: (2.1, -1.8) åƒç´ 
  åº”ç”¨ç¼©æ”¾: 1.05x
  åº”ç”¨å¼¹æ€§å˜å½¢: Î±=1000, Ïƒ=8

æ‰§è¡Œå¼ºåº¦å˜æ¢å¢å¼º...
  åº”ç”¨å¯¹æ¯”åº¦è°ƒæ•´: 1.15å€
  æ·»åŠ é«˜æ–¯å™ªå£°: Ïƒ=12.3 HU
  è¾“å‡ºèŒƒå›´æ£€æŸ¥: [-1000, 1000] HU

å¢å¼ºå®Œæˆ:
  åŸå§‹å›¾åƒå°ºå¯¸: (256, 256)
  å¢å¼ºå›¾åƒå°ºå¯¸: (256, 256)
  è§£å‰–ç»“æ„ä¿æŒ: æ˜¯
  ç—…ç†ç‰¹å¾ä¿æŒ: æ˜¯
```

**ç®—æ³•åˆ†æï¼š** åŒ»å­¦å›¾åƒå¢å¼ºé€šè¿‡å‡ ä½•å˜æ¢å’Œå¼ºåº¦å˜æ¢å¢åŠ äº†è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ã€‚ä»è¿è¡Œç»“æœå¯ä»¥çœ‹å‡ºï¼ŒCTå›¾åƒçš„æ—‹è½¬è§’åº¦é™åˆ¶åœ¨Â±5Â°ä»¥å†…ï¼Œå¹³ç§»èŒƒå›´é™åˆ¶åœ¨Â±5%ä»¥å†…ï¼Œç¡®ä¿äº†è§£å‰–ç»“æ„çš„åˆç†æ€§ã€‚å¼¹æ€§å˜å½¢å‚æ•°(Î±=1000, Ïƒ=8)æä¾›äº†é€‚åº¦çš„å½¢å˜å¼ºåº¦ï¼Œæ—¢å¢åŠ äº†æ•°æ®å¤šæ ·æ€§ï¼Œåˆä¿æŒäº†åŒ»å­¦å›¾åƒçš„ä¸´åºŠæ„ä¹‰ã€‚å™ªå£°æ·»åŠ æ¨¡æ‹Ÿäº†çœŸå®CTé‡‡é›†ä¸­çš„ç”µå­å™ªå£°ï¼Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚

**åŒ»å­¦å›¾åƒå¢å¼ºçš„æ ¸å¿ƒåŸåˆ™ï¼š**

1. **è§£å‰–åˆç†æ€§**ï¼šå˜æ¢åä»ä¿æŒè§£å‰–ç»“æ„çš„æ­£ç¡®æ€§
2. **ç—…ç†ä¿æŒ**ï¼šä¸æ”¹å˜æˆ–æ©ç›–å…³é”®çš„ç—…ç†ç‰¹å¾
3. **æ¨¡æ€ç‰¹æ€§**ï¼šé’ˆå¯¹ä¸åŒæˆåƒæ¨¡æ€è°ƒæ•´å¢å¼ºç­–ç•¥
4. **ä¸´åºŠç›¸å…³æ€§**ï¼šå¢å¼ºæ•ˆæœåº”å…·æœ‰å®é™…çš„ä¸´åºŠæ„ä¹‰
                    scale=(0.95, 1.05),  # å°å¹…åº¦ç¼©æ”¾
                    shear=5,  # å°å¹…åº¦å‰ªåˆ‡
                    fill=0  # å¡«å……ä¸ºé»‘è‰²
                ),
                transforms.RandomHorizontalFlip(p=0.5),  # æ°´å¹³ç¿»è½¬ï¼ˆå¯¹æŸäº›éƒ¨ä½æœ‰æ•ˆï¼‰
            ])
        else:
            # æ›´æ¿€è¿›çš„å˜æ¢ï¼ˆä»…ç”¨äºç ”ç©¶ç›®çš„ï¼‰
            transforms_list.extend([
                transforms.RandomAffine(
                    degrees=30,
                    translate=(0.15, 0.15),
                    scale=(0.8, 1.2),
                    shear=15,
                    fill=0
                ),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomVerticalFlip(p=0.3),
            ])

        return transforms.Compose(transforms_list)
```

### é«˜çº§å¢å¼ºæŠ€æœ¯

#### Mixupå’ŒCutMix

```python
import torch.nn.functional as F

class MedicalMixup:
    """
    åŒ»å­¦å›¾åƒMixupæŠ€æœ¯
    """
    def __init__(self, alpha=1.0, cutmix_prob=0.5):
        self.alpha = alpha
        self.cutmix_prob = cutmix_prob

    def mixup_data(self, x, y, alpha=1.0):
        """
        æ ‡å‡†Mixupå®ç°
        """
        if alpha > 0:
            lam = np.random.beta(alpha, alpha)
        else:
            lam = 1

        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)

        mixed_x = lam * x + (1 - lam) * x[index, :]
        y_a, y_b = y, y[index]

        return mixed_x, y_a, y_b, lam
```

---

## ğŸ¤– æ·±åº¦å­¦ä¹ é©±åŠ¨çš„å¢å¼ºç­–ç•¥

### å­¦ä¹ å¢å¼ºç­–ç•¥

#### è‡ªåŠ¨å¢å¼º

```python
import torch.optim as optim

class AutoAugmentation:
    """
    è‡ªåŠ¨å¢å¼ºç­–ç•¥å­¦ä¹ 
    """
    def __init__(self, num_policies=5, num_operations=10):
        self.num_policies = num_policies
        self.num_operations = num_operations
        self.policies = self._initialize_policies()

    def _initialize_policies(self):
        """
        åˆå§‹åŒ–å¢å¼ºç­–ç•¥
        """
        # åŒ»å­¦å›¾åƒç‰¹å®šçš„æ“ä½œ
        operations = [
            'rotate', 'translate_x', 'translate_y', 'shear_x', 'shear_y',
            'contrast', 'brightness', 'gamma', 'noise', 'blur'
        ]

        policies = []
        for _ in range(self.num_policies):
            policy = []
            for _ in range(2):  # æ¯ä¸ªç­–ç•¥åŒ…å«2ä¸ªå­æ“ä½œ
                op = np.random.choice(operations)
                prob = np.random.uniform(0.1, 0.9)
                magnitude = np.random.uniform(0.1, 1.0)
                policy.append((op, prob, magnitude))
            policies.append(policy)

        return policies
```

#### ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å¢å¼º

```python
import torch.nn as nn

class MedicalGAN:
    """
    åŒ»å­¦å›¾åƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œ
    """
    def __init__(self, latent_dim=100, image_size=(256, 256)):
        self.latent_dim = latent_dim
        self.image_size = image_size
        self.generator = self._build_generator()
        self.discriminator = self._build_discriminator()

    def _build_generator(self):
        """
        æ„å»ºç”Ÿæˆå™¨
        """
        class Generator(nn.Module):
            def __init__(self, latent_dim, channels=1):
                super().__init__()

                self.main = nn.Sequential(
                    # è¾“å…¥: latent_dim -> 4x4x512
                    nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),
                    nn.BatchNorm2d(512),
                    nn.ReLU(True),

                    # 128x128x16 -> 256x256x1
                    nn.ConvTranspose2d(16, channels, 4, 2, 1, bias=False),
                    nn.Tanh()
                )

            def forward(self, x):
                return self.main(x)

        return Generator(self.latent_dim)
```

---

## ğŸ”„ å›¾åƒæ¢å¤ä¸é‡å»ºæŠ€æœ¯

### å»å™ªå’Œä¼ªå½±å»é™¤

#### åŒ»å­¦å›¾åƒå»å™ª

```python
class MedicalImageDenoising:
    """
    åŒ»å­¦å›¾åƒå»å™ªæŠ€æœ¯
    """
    def __init__(self):
        pass

    def traditional_denoising(self, image, method='gaussian'):
        """
        ä¼ ç»Ÿå»å™ªæ–¹æ³•
        """
        if method == 'gaussian':
            return cv2.GaussianBlur(image, (5, 5), 0)

        elif method == 'median':
            return cv2.medianBlur(image, 5)

        elif method == 'bilateral':
            return cv2.bilateralFilter(image, 9, 75, 75)

        elif method == 'non_local_means':
            return cv2.fastNlMeansDenoising(image, None, 10, 7, 21)

        else:
            raise ValueError(f"Unknown denoising method: {method}")

    def wavelet_denoising(self, image, wavelet='db4', sigma=0.1):
        """
        å°æ³¢å»å™ª
        """
        import pywt

        # å¤šçº§å°æ³¢åˆ†è§£
        coeffs = pywt.wavedec2(image, wavelet, level=3)

        # ä¼°è®¡å™ªå£°æ°´å¹³
        # ä½¿ç”¨æœ€é«˜é¢‘å°æ³¢ç³»æ•°ä¼°è®¡å™ªå£°
        sigma_est = np.median(np.abs(coeffs[-1])) / 0.6745

        # é˜ˆå€¼å¤„ç†
        threshold = sigma_est * np.sqrt(2 * np.log(image.size))

        # è½¯é˜ˆå€¼
        coeffs_thresh = list(coeffs)
        coeffs_thresh[1:] = [pywt.threshold(detail, threshold, mode='soft')
                           for detail in coeffs_thresh[1:]]

        # é‡å»º
        denoised = pywt.waverec2(coeffs_thresh, wavelet)

        return denoised
```

### è¶…åˆ†è¾¨ç‡é‡å»º

#### å•å¹…å›¾åƒè¶…åˆ†è¾¨ç‡

```python
class MedicalSuperResolution:
    """
    åŒ»å­¦å›¾åƒè¶…åˆ†è¾¨ç‡
    """
    def __init__(self):
        pass

    def traditional_interpolation(self, image, scale_factor=2, method='bicubic'):
        """
        ä¼ ç»Ÿæ’å€¼æ–¹æ³•
        """
        if method == 'bicubic':
            h, w = image.shape
            new_h, new_w = int(h * scale_factor), int(w * scale_factor)
            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)

        elif method == 'bilinear':
            h, w = image.shape
            new_h, new_w = int(h * scale_factor), int(w * scale_factor)
            return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        else:
            raise ValueError(f"Unknown interpolation method: {method}")

class SRCNN(nn.Module):
    """
    è¶…åˆ†è¾¨ç‡å·ç§¯ç¥ç»ç½‘ç»œ
    """
    def __init__(self, num_channels=1):
        super().__init__()

        # ç‰¹å¾æå–
        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=4)
        self.relu1 = nn.ReLU(inplace=True)

        # éçº¿æ€§æ˜ å°„
        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=0)
        self.relu2 = nn.ReLU(inplace=True)

        # é‡å»º
        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=2)

    def forward(self, x):
        x = self.relu1(self.conv1(x))
        x = self.relu2(self.conv2(x))
        x = self.conv3(x)
        return x
```

---

## ğŸ“ å¢å¼ºæ•ˆæœè¯„ä¼°æŒ‡æ ‡

### å®šé‡è¯„ä¼°æŒ‡æ ‡

#### å›¾åƒè´¨é‡è¯„ä¼°

```python
class ImageQualityAssessment:
    """
    å›¾åƒè´¨é‡è¯„ä¼°
    """
    def __init__(self):
        pass

    def calculate_psnr(self, img1, img2, max_val=255.0):
        """
        è®¡ç®—å³°å€¼ä¿¡å™ªæ¯”
        """
        mse = np.mean((img1 - img2) ** 2)
        if mse == 0:
            return float('inf')
        return 20 * np.log10(max_val / np.sqrt(mse))

    def calculate_ssim(self, img1, img2):
        """
        è®¡ç®—ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°
        """
        from skimage.metrics import structural_similarity as ssim
        return ssim(img1, img2, data_range=255)

    def calculate_mae(self, img1, img2):
        """
        è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®
        """
        return np.mean(np.abs(img1 - img2))
```

#### ä»»åŠ¡å¯¼å‘è¯„ä¼°

```python
class TaskOrientedEvaluation:
    """
    ä»»åŠ¡å¯¼å‘çš„å¢å¼ºæ•ˆæœè¯„ä¼°
    """
    def __init__(self, segmentation_model=None, classification_model=None):
        self.segmentation_model = segmentation_model
        self.classification_model = classification_model

    def evaluate_segmentation_performance(self, original_images, enhanced_images, ground_truth_masks):
        """
        è¯„ä¼°åˆ†å‰²ä»»åŠ¡æ€§èƒ½
        """
        if self.segmentation_model is None:
            raise ValueError("Segmentation model not provided")

        results = {
            'original': [],
            'enhanced': []
        }

        for orig_img, enh_img, gt_mask in zip(original_images, enhanced_images, ground_truth_masks):
            # åŸå§‹å›¾åƒåˆ†å‰²
            orig_pred = self.segmentation_model.predict(orig_img)
            orig_metrics = self._calculate_segmentation_metrics(orig_pred, gt_mask)

            # å¢å¼ºå›¾åƒåˆ†å‰²
            enh_pred = self.segmentation_model.predict(enh_img)
            enh_metrics = self._calculate_segmentation_metrics(enh_pred, gt_mask)

            results['original'].append(orig_metrics)
            results['enhanced'].append(enh_metrics)

        # è®¡ç®—å¹³å‡æ€§èƒ½æå‡
        avg_orig = self._average_metrics(results['original'])
        avg_enh = self._average_metrics(results['enhanced'])

        improvement = {}
        for key in avg_orig.keys():
            improvement[key] = (avg_enh[key] - avg_orig[key]) / avg_orig[key] * 100

        return {
            'original_performance': avg_orig,
            'enhanced_performance': avg_enh,
            'improvement_percentage': improvement
        }
```

---

## ğŸ¥ ä¸´åºŠåº”ç”¨æ¡ˆä¾‹åˆ†æ

### æ•°æ®å¢å¼ºæ•ˆæœå¯¹æ¯”

#### ä¸åŒå¢å¼ºç­–ç•¥çš„æ€§èƒ½æ¯”è¾ƒ

```python
def compare_augmentation_strategies(model, train_data, val_data, strategies, num_epochs=10):
    """
    æ¯”è¾ƒä¸åŒå¢å¼ºç­–ç•¥çš„æ•ˆæœ
    """
    results = {}

    for strategy_name, augmentation in strategies.items():
        print(f"\nè®­ç»ƒç­–ç•¥: {strategy_name}")

        # åˆ›å»ºå¢å¼ºåçš„æ•°æ®åŠ è½½å™¨
        augmented_train_loader = create_augmented_loader(train_data, augmentation)

        # è®­ç»ƒæ¨¡å‹
        model_copy = copy.deepcopy(model)
        optimizer = optim.Adam(model_copy.parameters(), lr=0.001)

        training_history = []

        for epoch in range(num_epochs):
            model_copy.train()
            train_loss = 0.0

            for batch_idx, (data, targets) in enumerate(augmented_train_loader):
                optimizer.zero_grad()
                output = model_copy(data)
                loss = F.cross_entropy(output, targets)
                loss.backward()
                optimizer.step()

                train_loss += loss.item()

            # éªŒè¯
            val_accuracy = evaluate_model(model_copy, val_data)

            training_history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss / len(augmented_train_loader),
                'val_accuracy': val_accuracy
            })

            print(f'Epoch {epoch+1}, Loss: {train_loss/len(augmented_train_loader):.4f}, '
                  f'Val Acc: {val_accuracy:.4f}')

        results[strategy_name] = training_history

    return results
```

### å›¾åƒæ¢å¤æ¡ˆä¾‹åˆ†æ

#### è¶…åˆ†è¾¨ç‡åœ¨åŒ»å­¦å½±åƒä¸­çš„åº”ç”¨

```python
def super_resolution_case_study(lr_images, hr_images, model):
    """
    è¶…åˆ†è¾¨ç‡æ¡ˆä¾‹ç ”ç©¶
    """
    print("åŒ»å­¦å½±åƒè¶…åˆ†è¾¨ç‡æ¡ˆä¾‹ç ”ç©¶")
    print("=" * 50)

    # è¯„ä¼°åŸå§‹ä½åˆ†è¾¨ç‡å›¾åƒè´¨é‡
    print("\n1. ä½åˆ†è¾¨ç‡å›¾åƒè´¨é‡è¯„ä¼°:")
    for i, (lr, hr) in enumerate(zip(lr_images[:3], hr_images[:3])):
        psnr = calculate_psnr(lr, hr)
        ssim = calculate_ssim(lr, hr)
        print(f"å›¾åƒ {i+1}: PSNR = {psnr:.2f}dB, SSIM = {ssim:.4f}")

    # è¶…åˆ†è¾¨ç‡é‡å»º
    print("\n2. è¶…åˆ†è¾¨ç‡é‡å»º...")
    sr_images = []
    for lr in lr_images:
        sr = model(lr.unsqueeze(0).unsqueeze(0).float())
        sr_images.append(sr.squeeze().numpy())

    # è¯„ä¼°è¶…åˆ†è¾¨ç‡ç»“æœ
    print("\n3. è¶…åˆ†è¾¨ç‡ç»“æœè´¨é‡è¯„ä¼°:")
    improvements = {'psnr': [], 'ssim': []}

    for i, (lr, sr, hr) in enumerate(zip(lr_images[:3], sr_images[:3], hr_images[:3])):
        # è¶…åˆ†è¾¨ç‡åè´¨é‡
        sr_psnr = calculate_psnr(sr, hr)
        sr_ssim = calculate_ssim(sr, hr)

        # æ”¹è¿›é‡
        lr_psnr = calculate_psnr(lr, hr)
        lr_ssim = calculate_ssim(lr, hr)

        psnr_improvement = sr_psnr - lr_psnr
        ssim_improvement = sr_ssim - lr_ssim

        improvements['psnr'].append(psnr_improvement)
        improvements['ssim'].append(ssim_improvement)

        print(f"å›¾åƒ {i+1}:")
        print(f"  ä½åˆ†è¾¨ç‡: PSNR = {lr_psnr:.2f}dB, SSIM = {lr_ssim:.4f}")
        print(f"  è¶…åˆ†è¾¨ç‡: PSNR = {sr_psnr:.2f}dB, SSIM = {sr_ssim:.4f}")
        print(f"  æ”¹è¿›: PSNR +{psnr_improvement:.2f}dB, SSIM +{ssim_improvement:.4f}")

    # å¹³å‡æ”¹è¿›
    avg_psnr_improvement = np.mean(improvements['psnr'])
    avg_ssim_improvement = np.mean(improvements['ssim'])

    print(f"\n4. å¹³å‡æ”¹è¿›:")
    print(f"PSNRæ”¹è¿›: +{avg_psnr_improvement:.2f}dB")
    print(f"SSIMæ”¹è¿›: +{avg_ssim_improvement:.4f}")

    return {
        'average_psnr_improvement': avg_psnr_improvement,
        'average_ssim_improvement': avg_ssim_improvement,
        'sr_images': sr_images
    }
```

---

## ğŸ¯ æ ¸å¿ƒè¦ç‚¹ä¸å‘å±•æ–¹å‘

### 1. æ•°æ®å¢å¼ºæŠ€æœ¯
- **åŸºç¡€å¢å¼º**: å‡ ä½•å˜æ¢ã€å¼ºåº¦è°ƒæ•´ï¼Œä¿æŒè§£å‰–ç»“æ„
- **é«˜çº§å¢å¼º**: Mixupã€CutMixã€å¯¹æŠ—å¢å¼º
- **æ™ºèƒ½å¢å¼º**: AutoAugmentationã€GANç”Ÿæˆ

### 2. å›¾åƒæ¢å¤æ–¹æ³•
- **ä¼ ç»Ÿæ–¹æ³•**: æ»¤æ³¢å»å™ªã€æ’å€¼å¢å¼º
- **æ·±åº¦å­¦ä¹ **: DnCNNã€SRCNNã€EDSR
- **ä»»åŠ¡å¯¼å‘**: åŸºäºä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¼˜åŒ–

### 3. è¯„ä¼°æŒ‡æ ‡
- **å®¢è§‚æŒ‡æ ‡**: PSNRã€SSIMã€MAE
- **ä¸»è§‚è¯„ä¼°**: åŒ»ç”Ÿé˜…ç‰‡ä½“éªŒ
- **ä»»åŠ¡æŒ‡æ ‡**: åˆ†å‰²/åˆ†ç±»å‡†ç¡®ç‡æå‡

### 4. ä¸´åºŠåº”ç”¨æŒ‡å¯¼
- **æ¨¡æ€ç‰¹å¼‚æ€§**: é’ˆå¯¹ä¸åŒæˆåƒè®¾å¤‡çš„å¢å¼ºç­–ç•¥
- **æ•°æ®åˆè§„**: ä¿æŠ¤æ‚£è€…éšç§çš„å¢å¼ºæ–¹æ³•
- **å¯è§£é‡Šæ€§**: å¢å¼ºè¿‡ç¨‹çš„å¯è§£é‡Šæ€§

### 5. æœªæ¥å‘å±•æ–¹å‘
- **è‡ªé€‚åº”å¢å¼º**: æ ¹æ®å›¾åƒå†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
- **è·¨æ¨¡æ€å¢å¼º**: åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯æå‡å›¾åƒè´¨é‡
- **è”é‚¦å­¦ä¹ å¢å¼º**: åˆ†å¸ƒå¼æ•°æ®å¢å¼ºä¸éšç§ä¿æŠ¤

---

::: info ğŸ¯ ç« èŠ‚å®Œæˆ
é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†åŒ»å­¦å›¾åƒå¢å¼ºä¸æ¢å¤çš„æ ¸å¿ƒæŠ€æœ¯ã€‚ä»ä¼ ç»Ÿçš„å‡ ä½•å˜æ¢åˆ°å…ˆè¿›çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œä»ç®€å•çš„æ»¤æ³¢å»å™ªåˆ°å¤æ‚çš„æ·±åº¦å­¦ä¹ è¶…åˆ†è¾¨ç‡ï¼Œè¿™äº›æŠ€æœ¯å°†å¸®åŠ©ä½ è§£å†³åŒ»å­¦å½±åƒæ•°æ®ç¨€ç¼ºå’Œè´¨é‡é—®é¢˜ï¼Œä¸ºåç»­çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æä¾›æ›´å¥½çš„æ•°æ®åŸºç¡€ã€‚
:::